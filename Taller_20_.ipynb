{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseMurillo2882/JoseMurillo2882/blob/main/Taller_20_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urznMds5_wIV"
      },
      "source": [
        "**Importación de librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S8M5wyVouFpM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRC6dall_6eD"
      },
      "source": [
        "# Carga de datos\n",
        "\n",
        "La siguientes líneas de código nos permiten importar librerías propias de Google para cargar en el entorno de trabajo de Google Colab, los datos con los que vamos a trabajar en este tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "0pDbnB2tacC3",
        "outputId": "93b1f1ab-f6d3-4c85-d136-fa0a990c43b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a19821a-72ad-41d1-9c3b-0854f459ef4f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a19821a-72ad-41d1-9c3b-0854f459ef4f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4mgoKd6AJxc"
      },
      "source": [
        "Un Data Frame es una estructura en memoria que nos permite representar los datos leídos desde el archivo 'Taller01-Dataset-Clasificacion.csv' como si fueran una tabla de Excel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "bQgK94k7aknk",
        "outputId": "f939bffa-87da-46cb-c75d-4baad58f7624"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b4c4d8e2d713>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtaller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tesla-deaths.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tesla-deaths.csv'"
          ]
        }
      ],
      "source": [
        "taller = pd.read_csv('tesla-deaths.csv', sep=';')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdE7X_xqATnV"
      },
      "source": [
        "El método head() del objeto Data Frame (df) nos permite hacer una exploración rápida de los datos que tenemos cargados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "altNY-6ma6x5"
      },
      "outputs": [],
      "source": [
        "taller.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMBoatN5Ak7M"
      },
      "source": [
        "**Identificamos y manejamos los valores que faltan**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnqJTWFkBFLA"
      },
      "source": [
        "En el conjunto de datos, los datos que faltan vienen con el signo de interrogación \"¿?\".\n",
        "Reemplazamos \"?\" por NaN (Not a Number), que es el marcador de valor que falta predeterminado de Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORdpK0eha-GO"
      },
      "outputs": [],
      "source": [
        "taller.replace(\" ?\", np.nan, inplace = True)\n",
        "taller.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spli-oGdBa9d"
      },
      "source": [
        "La evaluación de los datos que faltan\n",
        "Los valores que faltan se convierten al valor predeterminado de Python. Utilizamos las funciones integradas de Python para identificar estos valores que faltan. Existen dos métodos para detectar los datos que faltan:\n",
        "\n",
        "\n",
        "1.  **isnull()**\n",
        "2.  **notnull()**\n",
        "\n",
        "La salida es un valor booleano que indica si el valor que se pasa al argumento de hecho faltan datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX4bJiH9vMqY"
      },
      "outputs": [],
      "source": [
        "missing_data = taller.isnull()\n",
        "missing_data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc75DmepB9NL"
      },
      "source": [
        "Contar los valores que faltan en cada columna\n",
        "Usando un bucle for en Python, podemos averiguar rápidamente el número de valores que faltan en cada columna. Como se mencionó anteriormente, \"True\" representa un valor que falta, \"False\" significa que el valor está presente en el conjunto de datos. En el cuerpo del bucle for, el método \".value_counts()\" cuenta el número de valores \"True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmQB6YXhvfgb"
      },
      "outputs": [],
      "source": [
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Evj70wCG_Q"
      },
      "source": [
        "**Tratar con los datos que faltan Tenemos las siguientes opciones**\n",
        "\n",
        "a. Dejar caer toda la fila\n",
        "\n",
        "B. Soltar toda la columna\n",
        "   reemplazar datos\n",
        "\n",
        "C. Reemplazarlo por la media\n",
        "\n",
        "D. Reemplazarlo por frecuencia\n",
        "\n",
        "E. Reemplazarlo en función de otras funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE4dbQuMDX5m"
      },
      "source": [
        "**Por último decidimos borrrar o dejemos caer todas las filas que no tienen datos.**\n",
        "\n",
        "Esta desicion es por que la falta de datos o los datos con \"?\" no son tan relevantes y la cantidad de datos faltantes es muy poca a consideracion del total de datos recogidos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNyGQ8S93anM"
      },
      "outputs": [],
      "source": [
        "#Para ello usamos el codigo --- taller.dropna(subset=[\"X\"], axis=0, inplace=True)\n",
        "\n",
        "taller.dropna(subset=[\"Pais-Origen\"],axis=0, inplace=True)\n",
        "taller.dropna(subset=[\"Ocupacion\"],axis=0, inplace=True)\n",
        "taller.dropna(subset=[\"Tipo-Trabajador\"],axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpefnxmlEMV2"
      },
      "outputs": [],
      "source": [
        "taller.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNqs269EEhRs"
      },
      "source": [
        "**Verificamos que los datos \"?\" desaparecieron**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvWOjUIs78fA"
      },
      "outputs": [],
      "source": [
        "taller.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4qsoy8FEsGL"
      },
      "source": [
        "\n",
        "El último paso en la limpieza de datos es comprobar y asegurarse de que todos los datos están en el formato correcto (int, float, text u otro).\n",
        "En Pandas, usamos\n",
        "\n",
        "**.dtype() para comprobar el tipo de datos**\n",
        "\n",
        "**.astype() para cambiar el tipo de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGRqUNal-X4m"
      },
      "outputs": [],
      "source": [
        "taller.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEIFqpjsFBW7"
      },
      "source": [
        "La función .unique () recupera todos los valores únicos de el array NumPy dada y ordena estos valores únicos.\n",
        "\n",
        "**Lo hacemos para ver como esta almacenada la variable en cada Columna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkiZGbAo9Sgr"
      },
      "outputs": [],
      "source": [
        "taller[\"Tipo-Trabajador\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ2x0LKqByuS"
      },
      "outputs": [],
      "source": [
        "taller[\"Nivel-Educacion\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnraqnHmB2tP"
      },
      "outputs": [],
      "source": [
        "taller[\"Estado-Civil\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4341q3cL_8UN"
      },
      "outputs": [],
      "source": [
        "taller[\"Ocupacion\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJLESEFQAQFU"
      },
      "outputs": [],
      "source": [
        "taller[\"Genero\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxiV1YYEAhRk"
      },
      "outputs": [],
      "source": [
        "taller[\"Pais-Origen\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sisfRnNtis77"
      },
      "outputs": [],
      "source": [
        "taller['Ingresos-Anuales'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtflaQJAGRlM"
      },
      "source": [
        "Definimos las variables X -Y que nos vas a relacionar la informacion que necesitamos clasificar.\n",
        "\n",
        "**Vamos a usar la X para los datos de las COLUMNAS**\n",
        "\n",
        "**VAmos a usar la Y para los valores de salida de X**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z-_37pe3eIM"
      },
      "outputs": [],
      "source": [
        "X = taller [['Tipo-Trabajador', 'Nivel-Educacion', 'Estado-Civil', 'Ocupacion', 'Genero', 'Pais-Origen']].values\n",
        "\n",
        "y = taller [['Ingresos-Anuales']].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtZUlO06GzVM"
      },
      "source": [
        "**En este paso realizamos la conversion de los datos tipo TEXTO o STRING**\n",
        "\n",
        "Algunas características son datos nominales o categóricos, tales como TIPO-TRABAJADOR, ESTADO-CIVIL, ETC.\n",
        "Los árboles de decisión en Sklearn no manejan variables categóricas. Es necesario codificar las variables categóricas en variables numéricas.\n",
        "\n",
        "Para realizar esta codificación podemos usar la clase LabelEncoder\n",
        "\n",
        "**Esta conversion es de TEXTO a NUMERICO para poderlos procesar en cada modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn79ea0vHGj7"
      },
      "source": [
        "Esto lo hacemos en cada COLUMA de datos que vamos a procesar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "objs3CmJ-K-3"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "le_Tipo_Trabajador = preprocessing.LabelEncoder()\n",
        "le_Tipo_Trabajador.fit([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov', ' Local-gov', ' Self-emp-inc', ' Without-pay'])\n",
        "X[:,0] = le_Tipo_Trabajador.transform(X[:,0])\n",
        "\n",
        "le_Nivel_Educacion = preprocessing.LabelEncoder()\n",
        "le_Nivel_Educacion.fit([' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' 7th-8th', ' Doctorate',\n",
        "                        ' Assoc-voc', ' Prof-school', ' 5th-6th', ' 10th', ' Preschool', ' 12th', ' 1st-4th'])\n",
        "X[:,1] = le_Nivel_Educacion.transform(X[:,1])\n",
        "\n",
        "le_Estado_Civil = preprocessing.LabelEncoder()\n",
        "le_Estado_Civil.fit([' Never-married', ' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Separated', ' Married-AF-spouse', ' Widowed'])\n",
        "X[:,2] = le_Estado_Civil.transform(X[:,2])\n",
        "\n",
        "le_Ocupacion = preprocessing.LabelEncoder()\n",
        "le_Ocupacion.fit([' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners', ' Prof-specialty', ' Other-service', ' Sales', ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct', ' Tech-support',\n",
        "                  ' Craft-repair', ' Protective-serv', ' Armed-Forces', ' Priv-house-serv'])\n",
        "X[:,3] = le_Ocupacion.transform(X[:,3])\n",
        "\n",
        "le_Genero = preprocessing.LabelEncoder()\n",
        "le_Genero.fit([' Male', ' Female'])\n",
        "X[:,4] = le_Genero.transform(X[:,4])\n",
        "\n",
        "le_Pais_Origen = preprocessing.LabelEncoder()\n",
        "le_Pais_Origen.fit([' United-States', ' Cuba', ' Jamaica', ' India', ' Mexico', ' Puerto-Rico', ' Honduras', ' England', ' Canada', ' Germany', ' Iran', ' Philippines', ' Poland', ' Columbia', ' Cambodia',\n",
        "                    ' Thailand', ' Ecuador', ' Laos', ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic', ' El-Salvador', ' France', ' Guatemala', ' Italy', ' China', ' South', ' Japan', ' Yugoslavia', ' Peru',\n",
        "                    ' Outlying-US(Guam-USVI-etc)', ' Scotland', ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong', ' Ireland', ' Hungary', ' Holand-Netherlands'])\n",
        "X[:,5] = le_Pais_Origen.transform(X[:,5])\n",
        "\n",
        "\n",
        "#le_Ingresos_Anuales = preprocessing.LabelEncoder()\n",
        "#le_Ingresos_Anuales.fit([' <=50K', ' >50K'])\n",
        "#y[:,0] = le_Ingresos_Anuales.transform(y[:,0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYzYTCwm--eN"
      },
      "source": [
        "#ARBOLES DE DESICION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3r85Ia6HRy7"
      },
      "source": [
        "# Antes de configurar el árbol de decisión, necesitamos dividir el conjunto de datos en dos:\n",
        "\n",
        "Conjunto de datos de entrenamiento.\n",
        "Conjunto de datos de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOqr-Q367zB_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.2,  random_state = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8N3pJqZMNU0"
      },
      "outputs": [],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xJebSb4KyoM"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "obtenido = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im79RwYSIlw_"
      },
      "source": [
        "**Creamos una variable nueva llada \"OBTENIDO\"**\n",
        "\n",
        "Con este paso entrenamos el arbol de decision con la funcion .fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ8FOZNh82VG"
      },
      "outputs": [],
      "source": [
        "obtenido.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNGVoJjKJLKy"
      },
      "source": [
        "**Verificamos la precision del modelo en los 2 conjuntos de datos**\n",
        "\n",
        "Para evaluar el modelo usaremos la métrica de precisión.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgQDOXO49A-s"
      },
      "outputs": [],
      "source": [
        "predTree = obtenido.predict(X_test)\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y_test, predTree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0DyGPEICC51"
      },
      "outputs": [],
      "source": [
        "predTree2 = obtenido.predict(X_train)\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y_train, predTree2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLObuhMeOCp8"
      },
      "source": [
        "**A continuación se muestra el árbol de manera GRAFICA.**\n",
        "\n",
        " Para el primer árbol se usa el método plot_tree(). Con este metodo se observa el ARBOL de manera GRAFICA\n",
        "\n",
        "Para el segundo árbol se usa el método export_text(). Con este metodo se observa el ARBOL de manera de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGHIW9tCVFl"
      },
      "outputs": [],
      "source": [
        "# Importar la clase que permite generar la gráfica\n",
        "from sklearn import tree\n",
        "\n",
        "# Obtener como una lista, el nombre de las columnas del dataset\n",
        "featureNames =  ['Tipo-Trabajador', 'Nivel-Educacion', 'Estado-Civil', 'Ocupacion', 'Genero', 'Pais-Origen']\n",
        "\n",
        "# Obtener como una lista, los posibles valores que toma la variable de respuesta\n",
        "classNames = targetNames = taller [\"Ingresos-Anuales\"].unique().tolist()\n",
        "\n",
        "# Crear los parámetros de visualización de la imagen\n",
        "fig = plt.subplots(figsize=(50, 50))\n",
        "\n",
        "# Generar y mostrar la gráfica del árbol\n",
        "tree.plot_tree(Ganancias, feature_names=featureNames, class_names=classNames, filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNq04hrjFkMJ"
      },
      "outputs": [],
      "source": [
        "# Importar la clase para generar el árbol\n",
        "from sklearn.tree import export_text\n",
        "t = export_text(Ganancias, feature_names=featureNames)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umUhDcno4lRq"
      },
      "source": [
        "El árbol de decisión, comienza con un único nodo en este caso \"Estado-Civil\" y luego se ramifica en resultados posibles que serian cada una de las columnas del dataset. Cada uno de esos resultados crea nodos adicionales, que se ramifican en otras posibilidades\n",
        "\n",
        "Hay tres tipos diferentes de nodos: nodos de probabilidad, nodos de decisión y nodos terminales.\n",
        "\n",
        "Un nodo de probabilidad, representado con las columas del dataset, muestra las probabilidades de ciertos resultados.\n",
        "\n",
        "Un nodo de decisión, representado con las lienas a otras probabilidades, muestra una decisión que se tomará.\n",
        "\n",
        "Un nodo terminal que es las base del ARBOL muestra el resultado definitivo de una ruta de decisión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqJAoG1L_UrT"
      },
      "source": [
        "#**Clasificación** KNN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCBJDdksQZpN"
      },
      "source": [
        "**Antes de configurar el modelo KNN, necesitamos dividir el conjunto de datos en dos:**\n",
        "\n",
        "Conjunto de datos de entrenamiento.\n",
        "Conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCI4DqTSYKLb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train2, X_test2 , y_train2, y_test2 = train_test_split(X, y, test_size = 0.3,  random_state = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QqmEir9QrAE"
      },
      "source": [
        "Vamos a crear el modelo con vecinos, la variable que va a\n",
        "representar el modelo la llamaremos TALLER1\n",
        "\n",
        "Entrenar el modelo K-NN con taller1.fit()\n",
        "\n",
        "Definimos una variable yhat que representa las predicciones del\n",
        "modelo (etiquetas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_9tHP_RiREx"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "taller1 = KNeighborsClassifier(n_neighbors = 5)\n",
        "taller1.fit(X_train2, y_train2)\n",
        "y_hat = taller1.predict(X_test2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h29AVATPwZLo"
      },
      "source": [
        "Para saber la Exactitud de mi modelo podemos aplicar el siguiente codigo.\n",
        "**Para el conjunto de ENTRENAMINETO Y DE PUREBAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkmI1XQkIgBV"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "train =metrics.accuracy_score(y_train2,taller1.predict(X_train2))\n",
        "test = metrics.accuracy_score(y_test2,taller1.predict(X_test2))\n",
        "print(\"ENTRENAMINETO =\",train)\n",
        "print(\"PRUEBAS=\",test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NZ2vsWYwcB9"
      },
      "source": [
        "**El resultado de las pruebas de exactitud de mi modelo es del 79%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MW1JVYpvVWf"
      },
      "source": [
        "La matriz de confusión es una herramienta para valorar que tan bueno es un modelo clasificación basado en aprendizaje automático. En particular, sirve para mostrar de forma explícita cuándo una clase es confundida con otra, lo cual nos, permite trabajar de forma separada con distintos tipos de error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDXpt68wxHjV"
      },
      "source": [
        "**Para Calcular la matris de confusion o el mapa de calor introducimos**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EoW_twZJyfX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "matriz = confusion_matrix(y_test2, y_hat)\n",
        "print (\"MATRIZ\")\n",
        "print(matriz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzQPtqPJxmTV"
      },
      "source": [
        "**En el EJE X encuentro la clasificacion real**\n",
        "\n",
        "**En el EJE Y encuentro la clasificacion de mi modelo**\n",
        "\n",
        "**0=MI MODELO**\n",
        "\n",
        "**1=CLASIFICACION REAL**\n",
        "\n",
        "**Ejmplo en el valor \"810\" se asignaron 810 observaciones la etiqueta \"0\" cuando en realidad son etiqueta \"1\" con lo que deducimos que ese valor es el error de clasificacion.**\n",
        "\n",
        "**Ejemplo en el valor \"1177\" se asignaron 1177 observaciones por lo que obtuvimos error de clasificacion**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loE12DaFwn7d"
      },
      "source": [
        "Para obtener de forma mas detallada de clasificacion de mi modelo introducimos este codigo\n",
        "**PARA EL CONJUNTO PRUEBAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FOXKqA8QNsT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "score = classification_report (y_test2, y_hat)\n",
        "print(\"Reporte Clasificacion\")\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hJzP24jv1v-"
      },
      "source": [
        "**La precision de mi modelo es del 0.79 = 79%**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJp_N6Z_qKc9"
      },
      "outputs": [],
      "source": [
        "#al crear la grafica me mostraba error: module 'seaborn' has no attribute 'heat'\n",
        "#from sklearn.metrics import classification_report\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "#import seaborn as sns\n",
        "\n",
        "#cuadro = confusion_matrix(y_test2, taller1.predict(X_test2))\n",
        "#plt.figure(figsize=(4, 4))\n",
        "#sns.heat(cuadro, square=True, annot=True, cbar=False, xticklabels=True)\n",
        "#plt.xlabel(\"Valores VERDADEROSl\")\n",
        "#plt.ylabel(\"Valores MODELO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_iXIJn7heXB"
      },
      "source": [
        "# REGRESION LINEAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgk0bgbPn2KS"
      },
      "source": [
        "**Para ello usamos la clase LinearRegression.**\n",
        "\n",
        "Los modelos siempre los creamos con los datos de entrenamiento.\n",
        "Primero creamos el modelo vacío model = LinearRegression().\n",
        "\n",
        "\n",
        "Luego metemos los datos de entrenamiento (A_train3, B_train3) en él.\n",
        "\n",
        "Para ello usamos el método fit() el método  requiere que los datos en la variable x sean de dos dimensiones: (n_samples, n_features). Por esta razón\n",
        "debemos ajustar la forma de los datos que tenemos actualmente en la variable x, que corresponde a un vector de una dimensión.\n",
        "\n",
        "**Para ello usamos el método reshape().**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7CeEVHqit3t"
      },
      "outputs": [],
      "source": [
        "#H = taller[['Ingresos-Anuales']].values                   Intente convertir los datos de INGRESOS ANUALES a nuemerico pero no me mostraba una grafica coherente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dNt4SPpjKUu"
      },
      "outputs": [],
      "source": [
        "#le_Ingresos_Anuales = preprocessing.LabelEncoder()\n",
        "#le_Ingresos_Anuales.fit([' <=50K', ' >50K'])             Utilize otros datos para realizar el metodo de regresion linel\n",
        "#H[:,0] = le_Ingresos_Anuales.transform(H[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLUdlFeMl5yW"
      },
      "outputs": [],
      "source": [
        "# Importación de la librería Scikit-Learn y el método train_test_split()\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#En la variable x tenemos los datos de la variable independiente\n",
        "A = np.asanyarray(taller['Horas-Semana'])\n",
        "\n",
        "# En la variable y tenemos os datos de la variable dependiente\n",
        "B = np.asanyarray(taller['Edad'])\n",
        "\n",
        "# Dividimos los datos en conjunto de pruebas y conjunto de validación\n",
        "# con una proporción de 20% para el conjunto de pruebas y 80% para\n",
        "# el conjunto de validación.\n",
        "A_train3, A_test3, B_train3, B_test3  = train_test_split(A, B, test_size=0.2, random_state=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RZU_0Beo8eC"
      },
      "source": [
        "La idea del modelo de regresión lineal simple es estimar los valores del intercepto y pendiente de la recta.\n",
        "\n",
        "Una vez se ha entrenado el modelo con el código de la celda anterior, estos coeficientes se pueden obtener mediante los atributos coef_ e intercept_ respectivamente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BelynmnsJSN0"
      },
      "outputs": [],
      "source": [
        "# Importación del modelo de Regresión lineal.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Creamos el modelo vacio\n",
        "model = LinearRegression()\n",
        "\n",
        "# Cambiamos la forma de la variable A, B de una dimensión a dos dimensiones\n",
        "A_train3 = A_train3.reshape(-1, 1)\n",
        "B_train3 = B_train3.reshape(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd3G7CHdYc1j"
      },
      "outputs": [],
      "source": [
        "# Metemos los datos de entrenamiento al modelo vacío\n",
        "model.fit(A_train3, B_train3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0fGThVrpQpa"
      },
      "source": [
        "Con los valores de pendiente e intercepto ya podemos escribir la ecuación que representa nuestro modelo de regresión:\n",
        "\n",
        "**y^=θ0+θ1x1**\n",
        "\n",
        "Reemplaza los valores y reescribe la ecuación.\n",
        "\n",
        "Para ello usamos el siguiente codigo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPYLwTBlyy7Y"
      },
      "outputs": [],
      "source": [
        "print('Coeficiente de la pendiente: ', model.coef_)\n",
        "print('Coeficiente del intercepto ', model.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzAkykaKy1QX"
      },
      "outputs": [],
      "source": [
        "plt.scatter(A_train3, B_train3, color='blue')\n",
        "plt.plot(A_train3, model.coef_[0]*A_train3 + model.intercept_, '-r')\n",
        "plt.xlabel('EDAD')\n",
        "plt.ylabel('HORAS-SEMANA')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGzEwgQe7SIf"
      },
      "source": [
        "**En este grafica intenta separar a la mitad todos los datos obeservados**\n",
        "\n",
        "**Es decir que la linea roja busca el punto en comun de los datos observados**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8T2DiGpjGZ"
      },
      "source": [
        "**Para evaluar/validar el modelo construido, comparamos los valores con el objetivo de calcular la exactitud del modelo de regresión.**\n",
        "\n",
        "Utilizamos MSE para calcular la exactitud de nuestro modelo basado en el conjunto de prueba:\n",
        "\n",
        "\n",
        "1.   Error Cuadrado Medio (MSE): El error cuadrado medio (MSE) es la media del error cuadrático. Es más popular que el error medio absoluto porque hace foco en grandes errores. Esto se debe a que el término cuadrático tiene errores más grandes que van creciendo en comparación con más pequeños.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta2ANEuKy3p-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "A_test3 = A_test3.reshape(-1,1)\n",
        "B_hat = model.predict(A_test3)\n",
        "\n",
        "print(\"Error medio absoluto: %.2f\" % np.mean(np.absolute(B_hat - B_test3)))\n",
        "print(\"Suma residual de los cuadrados (MSE): %.2f\" % np.mean((B_hat - B_test3) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(B_test3, B_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXk5H61LrQTi"
      },
      "source": [
        "# **MEJOR MODELO--CONCLUSIONES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2W9emZdrtPB"
      },
      "source": [
        "Bajo el analizis de datos de los 3 modelos implemetados\n",
        "\n",
        "El ARBOL DE DECISION nos a mostrado con mayor claridad el procesamineto de datos\n",
        "ya que este modelo logra miminizar las impuerazas de los nodos de cada division del DATASER por lo que son simples de entender y de interpretar.\n",
        "\n",
        "Ademas no requiere una preparación de los datos demasiado exigente (aunque la implementación de Scikit-Learn no soporta valores nulos\n",
        "\n",
        "Otra de las ventajes de el modelo Arbol de decision es que se puede trabajar tanto con variables cuantitativas como cualitativas y se puede combinar fácilmente con otras herramientas de toma de decisiones\n",
        "\n",
        "Sin enbargo cuando se presentan datos categóricos con múltiples niveles, la información obtenida se inclina a favor de los atributos con mayoría de niveles.\n",
        "\n",
        "Con relacion a este taller el ARBOL de DECISION fue el que para mi es el que mejor desempeño tuvo en la toma de decisiones tanto el la parte de interpretacion de datos graficas como la programacion.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0739FFBHIYU46n5MEQSLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}